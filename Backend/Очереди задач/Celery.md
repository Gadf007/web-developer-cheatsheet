# Celery

- [Описание](#описание)
- [Установка](#установка)
- [Запуск воркеров](#запуск-воркеров)
- [Использование](#использование)
- [Flower](#flower)
- [Советы](#советы)
- [Полезные ссылки](#полезные-ссылки)

## Описание

**Celery** — очередь задач, построенная на системе асинхронной передачи сообщений. В программировании, Celery можно использовать в качестве хранилища для отложенных задач. Программа, передавшая задачу, может беспрепятственно продолжать работать, а впоследствии она обращается к Celery для подтверждения окончания процесса вычисления, чтобы получить необходимые данные.

Несмотря на то, что celery написана на Python, работать с ней можно при использовании любого языка программирования при помощи **webhooks**.

Внедрение очереди задач в свое приложение позволит выгружать эти задачи и продолжать работать с пользовательским интерфейсом без каких-либо задержек. Таким образом, легко можно избежать блокировки GUI при запуске долгих и сложных вычислений.



## Установка

```bash
# Установка Celery
pip install celery
# Хак для Windows
pip install eventlet

# Установка Flower
pip install flower
```



## Запуск воркеров

```bash
# Запуск Celery (Unix)
celery -A main worker -Q queue1 -l info --autoscale=7,1 -n worker1
# Запуск Celery (Windows)
celery -A main worker -l info -P eventlet
# Запуск Celery вместе с Flower
celery -A main flower --port=8031 --url_prefix=flower
```



## Использование

Файл `main/settings.py`

```python
# Если RabbitMQ
RABBITMQ_USER = 'user1'
RABBITMQ_PASSWORD = 'pass'
RABBITMQ_HOST = 'localhost'
RABBITMQ_PORT = 5672
RABBITMQ_VHOST = 'host1'
CELERY_BROKER_URL = 'amqp://{}:{}@{}:{}/{}'.format(RABBITMQ_USER, RABBITMQ_PASSWORD, RABBITMQ_HOST, RABBITMQ_PORT, RABBITMQ_VHOST)
# Если Redis
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
REDIS_DB_NUMBER = 1
CELERY_RESULT_BACKEND = 'redis'
CELERY_BROKER_URL = 'redis://{}:{}/{}'.format(REDIS_HOST, REDIS_PORT, REDIS_DB_NUMBER)
# Общие настройки
CELERY_IMPORTS = ['optimizer.tasks']
CELERY_DEFAULT_QUEUE = 'queue1'
CELERY_ENABLE_UTC = False
CELERY_TIMEZONE = 'Europe/Moscow'
```

Файл `main/celery.py`

```python
import os
from celery import Celery

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'main.settings')
celery_app = Celery('app1')
celery_app.config_from_object('django.conf:settings', namespace='CELERY')
celery_app.autodiscover_tasks()
```

Файл `main/__init__.py`

```python
from .celery import celery_app

__all__ = ['celery_app']
```

Файл `app/tasks.py`

```python
from __future__ import absolute_import, unicode_literals
from main import celery_app

@celery_app.task(autoretry_for=(Exception,), bind=True, max_retries=20, ignore_result=True)
def send_notification(self, user_id):
	# Some actions...
	pass
```

Где-то в функции, которая создает задачу

```python
send_notification.delay(user.id)
```



## Flower

**Flower** — веб-инструмент для мониторинга и администрирования кластеров Celery.

**Возможности:**

- Мониторинг в реальном времени с помощью **Celery Events**
	- Ход выполнения и история
	- Возможность показать детали задачи (аргументы, время запуска, время выполнения и многое другое)
	- Графики и статистика
- Дистанционное управление
	- Просмотр статуса воркера
	- Завершение работы и перезапуск воркеров
	- Управление размером рабочего пула и настройками автомасштабирования
	- Просмотр и изменение очередей
	- Просмотр текущих / запланированных / отозванных задач



## Советы

### Не используйте базу данных в качестве broker/backend

**Брокер** отвечает за передачу сообщений (задач) между так называемыми исполнителями (workers). Проблема использования базы данных заключается в ее ограничениях - она просто не предназначена для этого. Дело в том, что с ростом количества исполнителей, нагрузка на базу будет только возрастать, а учитывая тот факт, что каждый worker имеет еще ряд потоков, ситуация может стать катастрофической даже при малых нагрузках. Все это приведет к бутылочному горлышку в виде затыка на I/O, потере задач, а возможно и неоднократному их исполнению (два воркера могут получить одну и ту же задачу на исполнение).

### Разделяйте задачи по очередям

По мере развития приложения, в проекте будут появляться критичные для выполнения задачи: проверка статуса платежа, формирование отчета, отправка электронных писем и так далее. Терять их недопустимо. Если все задачи складировать в одну очередь, то в один прекрасный момент она может забиться, поставив под угрозу выполнение критически важного кода. **Разделяйте очереди по приоритетам**:

- High
- Normal
- Low

### Логируйте ошибки

Очень важно иметь полную картину происходящего внутри кода. По-умолчанию Celery все ошибки пишет в `stderr`, а прочая информация, связанная с исполнением попадает в stdout. Контролировать вывод ошибок можно через стандартный `logging`, достаточно повесить свой handler на logger под названием `celery`. Практика развертывания боевых приложений, использующих Celery, показывает, что в качестве процесс-менеджера используют supervisord. В его настройках можно задавать путь до файла в который он будет складировать всю информацию, генерируемую демоном.

### Пишите задачи маленькими

При написании задач старайтесь придерживаться принципа минимализма кода. То есть не нужно в самом celery task описывать бизнес логику задачи.

### "Гасите" задачи вовремя

Явно указывайте лимит на выполнение задачи. Это можно сделать несколькими способами:

- Через декоратор `@app.task`, передавая `soft_time_limit`, `time_limit`.
- Глобально задать таймлимит при запуске исполнителя (worker), передав ему соответствующие аргументы (их можно найти в документации к Celery). В этом случае для всех задач, попадающих в заданную очередь будет один и тот же таймлимит.

Указание таймлимита очень важно, так как в некоторых случаях его отсутствие попросту приведет к "зависанию" исполнителя при выполнении неоднозначных задач (требующих длительного времени, коннект к внешнему сервису и так далее).

### Не храните результаты исполнения без необходимости

В большинстве случаев результат выполнения задачи не нужен (например, если происходит отправка письма). В такой ситуации нет необходимости хранить что-то. Если ваши задачи полностью попадают в эту категорию, то в настройках Celery можно задать глобальный параметр `CELERY_IGNORE_RESULT = True`, который будет игнорировать результат исполнения всех task-функций.

### Используйте Flower для мониторинга исполнения задач

Всегда используйте **Flower** при работе с Celery. Данный инструмент это небольшое веб приложение, написанное с использованием микрофреймворка **Flask**, а также **Tornado** для поддержки веб-сокетов. Flower позволяет всегда быть в курсе того как исполняются ваши задачи.

### Не передавайте ORM объекты в качестве аргументов

Вы не должны передавать объекты базы данных, например, модель пользователя в фоновую задачу, так как в сериализованном объекте могут оказаться уже устаревшие и некорректные данные. Если необходимо, то передавайте в задачу ID пользователя, а в самой задаче запрашивайте базу об этом пользователе.

### BROKER_TRANSPORT_OPTIONS и visibility_timeout

При использовании Celery нередко приходиться прибегать к помощи отложенных задач, используя `apply_async` и передавая аргументы `eta` или `countdown`. Но делать это нужно осторожно, так как даже здесь нас поджидают "подводные камни". О чем речь? Очень часто у разработчиков, начинающих использовать очередь задач вроде Celery, происходят аномалии вроде выполнения одного и того же таска несколькими воркерами одновременно. Так может происходить по причине того, что время, через которое должна выполниться задача, превышает `visibility_timeout`. По умолчанию для Redis этот параметр равен 1 часу. То есть если вы укажете выполнение задачи через 2 часа, то демон celery подождет 1 час, поймет, что никто из доступных воркеров не откликнулся и насильно назначит всем воркерам ее выполнение при наступлении дедлайна.

### Long-running tasks

Старайтесь не использовать Celery для выполнения долгих задач. На этот аргумент есть ряд причин:

- Процессы, живущие долго, потребляют память, но не освобождают ее. Даже с учетом работы сборщика мусора. Такой механизм необходим, чтобы избежать фрагментации оперативной памяти
- Celery заточен на выполнение большого количества задач, требующих мало времени на их исполнение. Когда задачи тяжелые и выполняются долго, образуются очереди

Долгоживущие процессы имеют тенденцию к пожиранию памяти, но вот назад ее зачастую не возвращают, поэтому в контексте использования Celery с ними иногда имеет смысл перезагружать воркеры после выполнения заданного количества тасков. За это отвечает параметр `CELERYD_MAX_TASKS_PER_CHILD`.



## Полезные ссылки

- [Оригинал статьи](https://khashtamov.com/ru/celery-best-practices/)
- [Документация](http://docs.celeryproject.org/en/latest/)
- [Очередь сообщений и асинхронные задачи с помощью Celery и RabbitMQ](http://devacademy.ru/posts/ochered-soobschenij-i-asinhronnyie-zadachi-s-pomoschyu-celery-i-rabbitmq/)